{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7yQQTA9IGDt8"
   },
   "source": [
    "<img src=\"https://fsdl.me/logo-720-dark-horizontal\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MX9n-Zed8G_T"
   },
   "source": [
    "# Lab 07: Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What You Will Learn\n",
    "\n",
    "- How to convert PyTorch models into portable TorchScript binaries\n",
    "- How to use `gradio` to make a simple demo UI for your ML-powered applications\n",
    "- How to split out a model service from the frontend and spin up a publicly accessible application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "45D6GuSwvT7d"
   },
   "outputs": [],
   "source": [
    "lab_idx = 7\n",
    "\n",
    "\n",
    "if \"bootstrap\" not in locals() or bootstrap.run:\n",
    "    # path management for Python\n",
    "    pythonpath, = !echo $PYTHONPATH\n",
    "    if \".\" not in pythonpath.split(\":\"):\n",
    "        pythonpath = \".:\" + pythonpath\n",
    "        %env PYTHONPATH={pythonpath}\n",
    "        !echo $PYTHONPATH\n",
    "\n",
    "    # get both Colab and local notebooks into the same state\n",
    "    !wget --quiet https://fsdl.me/gist-bootstrap -O bootstrap.py\n",
    "    import bootstrap\n",
    "\n",
    "    # change into the lab directory\n",
    "    bootstrap.change_to_lab_dir(lab_idx=lab_idx)\n",
    "\n",
    "    bootstrap.run = False  # change to True re-run setup\n",
    "    \n",
    "!pwd\n",
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change to the current directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\RL_Finance\\MLops\\fslab\\lab07\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"D:/RL_Finance/MLops/fslab/lab07\")\n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "pzi8qYKI-njP"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.output_result { max-width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML, IFrame\n",
    "\n",
    "full_width = True\n",
    "frame_height = 720  # adjust for your screen\n",
    "\n",
    "if full_width:  # if we want the notebook to take up the whole width\n",
    "    # add styling to the notebook's HTML directly\n",
    "    display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "    display(HTML(\"<style>.output_result { max-width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Follow along with a video walkthrough on YouTube:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"720\"\n",
       "            src=\"https://fsdl.me/2022-lab-07-video-embed\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1dd7cc2cbb0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "\n",
    "\n",
    "IFrame(src=\"https://fsdl.me/2022-lab-07-video-embed\", width=\"100%\", height=720)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SAw7BEI_sCZZ"
   },
   "source": [
    "# Making the model portable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8zL0K2Xe-MWJ"
   },
   "source": [
    "While training the model,\n",
    "we've saved checkpoints and stored them locally\n",
    "and on W&B.\n",
    "\n",
    "From these checkpoints, we can reload model weights\n",
    "and even restart training if we are in or can recreate\n",
    "the model development environment.\n",
    "\n",
    "We could directly deploy these checkpoints into production,\n",
    "but they're suboptimal for two reasons.\n",
    "\n",
    "First, as the name suggests,\n",
    "these \"checkpoints\" are designed for serializing\n",
    "state at a point of time in training.\n",
    "\n",
    "That means they can include lots of information\n",
    "not relevant during inference,\n",
    "e.g. optimizer states like running average gradients.\n",
    "\n",
    "Additionally, the model development environment\n",
    "is much more heavyweight than what we need during inference.\n",
    "\n",
    "For example, we've got Lightning for training models\n",
    "and W&B for tracking training runs.\n",
    "\n",
    "These in turn incur dependencies on lots of heavy data science libraries.\n",
    "\n",
    "We don't need this anymore -- we just want to run the model.\n",
    "\n",
    "These are effectively \"compiler tools\", which our runtime model doesn't need.\n",
    "\n",
    "So we need a new model binary artifact for runtime\n",
    "that's leaner and more independent.\n",
    "\n",
    "For this purpose, we use TorchScript."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0bMPqKDjs623"
   },
   "source": [
    "## Compiling models to TorchScript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7d9EmZ0j_AQF"
   },
   "source": [
    "Torch has two main facilities for creating\n",
    "more portable model binaries:\n",
    "_scripting_ and _tracing_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h9PVzwjQ_YHg"
   },
   "source": [
    "Scripting produces a binary that combines\n",
    "constant `Tensor` values\n",
    "(like weights and positional embeddings)\n",
    "with a program that describes how to use them.\n",
    "\n",
    "The result is a program that creates a dynamic graph,\n",
    "as does a normal PyTorch program,\n",
    "but this program is written in a\n",
    "sub-dialect of Python called\n",
    "_TorchScript_.\n",
    "\n",
    "The [TorchScript sub-dialect of Python](https://pytorch.org/docs/stable/jit_language_reference.html#language-reference)\n",
    "is more performant\n",
    "and can even be run without a Python interpreter.\n",
    "\n",
    "For example, TorchScript programs can be executed in pure C++\n",
    "[using LibTorch](https://pytorch.org/tutorials/advanced/cpp_export.html).\n",
    "\n",
    "You can read more in the documentation for the primary method\n",
    "for scripting models, `torch.jit.script`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "h1VtGt_Xj_H7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mSignature:\u001b[0m\n",
      "\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscript\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0moptimize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0m_frames_up\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0m_rcb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mexample_inputs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSource:\u001b[0m   \n",
      "\u001b[1;32mdef\u001b[0m \u001b[0mscript\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0moptimize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0m_frames_up\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0m_rcb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mexample_inputs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34mr\"\"\"Script the function.\n",
      "\n",
      "    Scripting a function or ``nn.Module`` will inspect the source code, compile\n",
      "    it as TorchScript code using the TorchScript compiler, and return a :class:`ScriptModule` or\n",
      "    :class:`ScriptFunction`. TorchScript itself is a subset of the Python language, so not all\n",
      "    features in Python work, but we provide enough functionality to compute on\n",
      "    tensors and do control-dependent operations. For a complete guide, see the\n",
      "    :ref:`language-reference`.\n",
      "\n",
      "    Scripting a dictionary or list copies the data inside it into a TorchScript instance than can be\n",
      "    subsequently passed by reference between Python and TorchScript with zero copy overhead.\n",
      "\n",
      "    ``torch.jit.script`` can be used as a function for modules, functions, dictionaries and lists\n",
      "     and as a decorator ``@torch.jit.script`` for :ref:`torchscript-classes` and functions.\n",
      "\n",
      "    Args:\n",
      "        obj (Callable, class, or nn.Module):  The ``nn.Module``, function, class type,\n",
      "                                                  dictionary, or list to compile.\n",
      "        example_inputs (Union[List[Tuple], Dict[Callable, List[Tuple]], None]): Provide example inputs\n",
      "            to annotate the arguments for a function or ``nn.Module``.\n",
      "\n",
      "    Returns:\n",
      "        If ``obj`` is ``nn.Module``, ``script`` returns\n",
      "        a :class:`ScriptModule` object. The returned :class:`ScriptModule` will\n",
      "        have the same set of sub-modules and parameters as the\n",
      "        original ``nn.Module``. If ``obj`` is a standalone function,\n",
      "        a :class:`ScriptFunction` will be returned. If ``obj`` is a ``dict``, then\n",
      "        ``script`` returns an instance of `torch._C.ScriptDict`. If ``obj`` is a ``list``,\n",
      "        then ``script`` returns an instance of `torch._C.ScriptList`.\n",
      "\n",
      "    **Scripting a function**\n",
      "        The ``@torch.jit.script`` decorator will construct a :class:`ScriptFunction`\n",
      "        by compiling the body of the function.\n",
      "\n",
      "        Example (scripting a function):\n",
      "\n",
      "        .. testcode::\n",
      "\n",
      "            import torch\n",
      "\n",
      "            @torch.jit.script\n",
      "            def foo(x, y):\n",
      "                if x.max() > y.max():\n",
      "                    r = x\n",
      "                else:\n",
      "                    r = y\n",
      "                return r\n",
      "\n",
      "            print(type(foo))  # torch.jit.ScriptFunction\n",
      "\n",
      "            # See the compiled graph as Python code\n",
      "            print(foo.code)\n",
      "\n",
      "            # Call the function using the TorchScript interpreter\n",
      "            foo(torch.ones(2, 2), torch.ones(2, 2))\n",
      "\n",
      "        .. testoutput::\n",
      "            :hide:\n",
      "\n",
      "            ...\n",
      "\n",
      "    ****Scripting a function using example_inputs**\n",
      "        Example inputs can be used to annotate a function arguments.\n",
      "\n",
      "        Example (annotating a function before scripting):\n",
      "\n",
      "        .. testcode::\n",
      "\n",
      "            import torch\n",
      "\n",
      "            def test_sum(a, b):\n",
      "                return a + b\n",
      "\n",
      "            # Annotate the arguments to be int\n",
      "            scripted_fn = torch.jit.script(test_sum, example_inputs=[(3, 4)])\n",
      "\n",
      "            print(type(scripted_fn))  # torch.jit.ScriptFunction\n",
      "\n",
      "            # See the compiled graph as Python code\n",
      "            print(scripted_fn.code)\n",
      "\n",
      "            # Call the function using the TorchScript interpreter\n",
      "            scripted_fn(20, 100)\n",
      "\n",
      "        .. testoutput::\n",
      "            :hide:\n",
      "\n",
      "            ...\n",
      "\n",
      "    **Scripting an nn.Module**\n",
      "        Scripting an ``nn.Module`` by default will compile the ``forward`` method and recursively\n",
      "        compile any methods, submodules, and functions called by ``forward``. If a ``nn.Module`` only uses\n",
      "        features supported in TorchScript, no changes to the original module code should be necessary. ``script``\n",
      "        will construct :class:`ScriptModule` that has copies of the attributes, parameters, and methods of\n",
      "        the original module.\n",
      "\n",
      "        Example (scripting a simple module with a Parameter):\n",
      "\n",
      "        .. testcode::\n",
      "\n",
      "            import torch\n",
      "\n",
      "            class MyModule(torch.nn.Module):\n",
      "                def __init__(self, N, M):\n",
      "                    super().__init__()\n",
      "                    # This parameter will be copied to the new ScriptModule\n",
      "                    self.weight = torch.nn.Parameter(torch.rand(N, M))\n",
      "\n",
      "                    # When this submodule is used, it will be compiled\n",
      "                    self.linear = torch.nn.Linear(N, M)\n",
      "\n",
      "                def forward(self, input):\n",
      "                    output = self.weight.mv(input)\n",
      "\n",
      "                    # This calls the `forward` method of the `nn.Linear` module, which will\n",
      "                    # cause the `self.linear` submodule to be compiled to a `ScriptModule` here\n",
      "                    output = self.linear(output)\n",
      "                    return output\n",
      "\n",
      "            scripted_module = torch.jit.script(MyModule(2, 3))\n",
      "\n",
      "        Example (scripting a module with traced submodules):\n",
      "\n",
      "        .. testcode::\n",
      "\n",
      "            import torch\n",
      "            import torch.nn as nn\n",
      "            import torch.nn.functional as F\n",
      "\n",
      "            class MyModule(nn.Module):\n",
      "                def __init__(self):\n",
      "                    super().__init__()\n",
      "                    # torch.jit.trace produces a ScriptModule's conv1 and conv2\n",
      "                    self.conv1 = torch.jit.trace(nn.Conv2d(1, 20, 5), torch.rand(1, 1, 16, 16))\n",
      "                    self.conv2 = torch.jit.trace(nn.Conv2d(20, 20, 5), torch.rand(1, 20, 16, 16))\n",
      "\n",
      "                def forward(self, input):\n",
      "                    input = F.relu(self.conv1(input))\n",
      "                    input = F.relu(self.conv2(input))\n",
      "                    return input\n",
      "\n",
      "            scripted_module = torch.jit.script(MyModule())\n",
      "\n",
      "        To compile a method other than ``forward`` (and recursively compile anything it calls), add\n",
      "        the :func:`@torch.jit.export <torch.jit.export>` decorator to the method. To opt out of compilation\n",
      "        use :func:`@torch.jit.ignore <torch.jit.ignore>` or :func:`@torch.jit.unused <torch.jit.unused>`.\n",
      "\n",
      "        Example (an exported and ignored method in a module)::\n",
      "\n",
      "            import torch\n",
      "            import torch.nn as nn\n",
      "\n",
      "            class MyModule(nn.Module):\n",
      "                def __init__(self):\n",
      "                    super().__init__()\n",
      "\n",
      "                @torch.jit.export\n",
      "                def some_entry_point(self, input):\n",
      "                    return input + 10\n",
      "\n",
      "                @torch.jit.ignore\n",
      "                def python_only_fn(self, input):\n",
      "                    # This function won't be compiled, so any\n",
      "                    # Python APIs can be used\n",
      "                    import pdb\n",
      "                    pdb.set_trace()\n",
      "\n",
      "                def forward(self, input):\n",
      "                    if self.training:\n",
      "                        self.python_only_fn(input)\n",
      "                    return input * 99\n",
      "\n",
      "            scripted_module = torch.jit.script(MyModule())\n",
      "            print(scripted_module.some_entry_point(torch.randn(2, 2)))\n",
      "            print(scripted_module(torch.randn(2, 2)))\n",
      "\n",
      "        Example ( Annotating forward of nn.Module using example_inputs)::\n",
      "\n",
      "            import torch\n",
      "            import torch.nn as nn\n",
      "            from typing import NamedTuple\n",
      "\n",
      "            class MyModule(NamedTuple):\n",
      "            result: List[int]\n",
      "\n",
      "            class TestNNModule(torch.nn.Module):\n",
      "                def forward(self, a) -> MyModule:\n",
      "                    result = MyModule(result=a)\n",
      "                    return result\n",
      "\n",
      "            pdt_model = TestNNModule()\n",
      "\n",
      "            # Runs the pdt_model in eager model with the inputs provided and annotates the arguments of forward\n",
      "            scripted_model = torch.jit.script(pdt_model, example_inputs={pdt_model: [([10, 20, ], ), ], })\n",
      "\n",
      "            # Run the scripted_model with actual inputs\n",
      "            print(scripted_model([20]))\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_enabled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mglobal\u001b[0m \u001b[0m_TOPLEVEL\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[0m_TOPLEVEL\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mlog_torchscript_usage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"script\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mprev\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_TOPLEVEL\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0m_TOPLEVEL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0m_script_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0moptimize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0m_frames_up\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_frames_up\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0m_rcb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_rcb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mexample_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexample_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0m_TOPLEVEL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprev\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFile:\u001b[0m      c:\\users\\xiang\\anaconda3\\lib\\site-packages\\torch\\jit\\_script.py\n",
      "\u001b[1;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "torch.jit.script??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tUOm7G9ESi4s"
   },
   "source": [
    "The primary alternative to scripting is _tracing_,\n",
    "which runs the PyTorch module on a specific\n",
    "set of inputs and records, or \"traces\",\n",
    "the compute graph.\n",
    "\n",
    "You can read more about it in the documentation for the primary method\n",
    "for tracing models, `torch.jit.trace`,\n",
    "or just read the quick summary and comparison below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Pn3QLOFNjuOa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mSignature:\u001b[0m\n",
      "\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mexample_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0moptimize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mcheck_trace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mcheck_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mcheck_tolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-05\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mstrict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0m_force_outplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0m_module_class\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0m_compilation_unit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m<\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCompilationUnit\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mat\u001b[0m \u001b[1;36m0x000001DD23A51FF0\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mexample_kwarg_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0m_store_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSource:\u001b[0m   \n",
      "\u001b[1;32mdef\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mexample_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0moptimize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mcheck_trace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mcheck_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mcheck_tolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mstrict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0m_force_outplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0m_module_class\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0m_compilation_unit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_python_cu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mexample_kwarg_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0m_store_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34mr\"\"\"\n",
      "    Trace a function and return an executable  or :class:`ScriptFunction` that will be optimized using just-in-time compilation.\n",
      "\n",
      "    Tracing is ideal for code that operates only on\n",
      "    ``Tensor``\\\\s and lists, dictionaries, and\n",
      "    tuples of ``Tensor``\\\\s.\n",
      "\n",
      "    Using `torch.jit.trace` and `torch.jit.trace_module`, you can turn an\n",
      "    existing module or Python function into a TorchScript\n",
      "    :class:`ScriptFunction` or :class:`ScriptModule`. You must provide example\n",
      "    inputs, and we run the function, recording the operations performed on all\n",
      "    the tensors.\n",
      "\n",
      "    * The resulting recording of a standalone function produces `ScriptFunction`.\n",
      "    * The resulting recording of `nn.Module.forward` or `nn.Module` produces\n",
      "      `ScriptModule`.\n",
      "\n",
      "    This module also contains any parameters that the original\n",
      "    module had as well.\n",
      "\n",
      "    Warning:\n",
      "        Tracing only correctly records functions and modules which are not data\n",
      "        dependent (e.g., do not have conditionals on data in tensors) and do not have\n",
      "        any untracked external dependencies (e.g., perform input/output or\n",
      "        access global variables). Tracing only records operations done when the given\n",
      "        function is run on the given tensors. Therefore, the returned\n",
      "        `ScriptModule` will always run the same traced graph on any input. This\n",
      "        has some important implications when your module is expected to run\n",
      "        different sets of operations, depending on the input and/or the module\n",
      "        state. For example,\n",
      "\n",
      "        * Tracing will not record any control-flow like if-statements or loops.\n",
      "          When this control-flow is constant across your module, this is fine\n",
      "          and it often inlines the control-flow decisions. But sometimes the\n",
      "          control-flow is actually part of the model itself. For instance, a\n",
      "          recurrent network is a loop over the (possibly dynamic) length of an\n",
      "          input sequence.\n",
      "        * In the returned :class:`ScriptModule`, operations that have different\n",
      "          behaviors in ``training`` and ``eval`` modes will always behave as if\n",
      "          it is in the mode it was in during tracing, no matter which mode the\n",
      "          `ScriptModule` is in.\n",
      "\n",
      "        In cases like these, tracing would not be appropriate and\n",
      "        :func:`scripting <torch.jit.script>` is a better choice. If you trace\n",
      "        such models, you may silently get incorrect results on subsequent\n",
      "        invocations of the model. The tracer will try to emit warnings when\n",
      "        doing something that may cause an incorrect trace to be produced.\n",
      "\n",
      "    Args:\n",
      "        func (callable or torch.nn.Module):  A Python function or `torch.nn.Module`\n",
      "            that will be run with `example_inputs`. `func` arguments and return\n",
      "            values  must be tensors or (possibly nested) tuples that contain\n",
      "            tensors. When a module is passed `torch.jit.trace`, only the\n",
      "            ``forward`` method is run and traced (see :func:`torch.jit.trace\n",
      "            <torch.jit.trace_module>` for details).\n",
      "\n",
      "    Keyword arguments:\n",
      "        example_inputs (tuple or torch.Tensor or None, optional): A tuple of example\n",
      "            inputs that will be passed to the function while tracing.\n",
      "            Default: ``None``. Either this argument or ``example_kwarg_inputs``\n",
      "            should be specified. The resulting trace can be run with inputs of\n",
      "            different types and shapes assuming the traced operations support those\n",
      "            types and shapes. `example_inputs` may also be a single Tensor in which\n",
      "            case it is automatically wrapped in a tuple. When the value is None,\n",
      "            ``example_kwarg_inputs`` should be specified.\n",
      "\n",
      "        check_trace (``bool``, optional): Check if the same inputs run through\n",
      "            traced code produce the same outputs. Default: ``True``. You might want\n",
      "            to disable this if, for example, your network contains non-\n",
      "            deterministic ops or if you are sure that the network is correct despite\n",
      "            a checker failure.\n",
      "\n",
      "        check_inputs (list of tuples, optional): A list of tuples of input\n",
      "            arguments that should be used to check the trace against what is\n",
      "            expected. Each tuple is equivalent to a set of input arguments that\n",
      "            would be specified in ``example_inputs``. For best results, pass in\n",
      "            a set of checking inputs representative of the space of shapes and\n",
      "            types of inputs you expect the network to see.  If not specified,\n",
      "            the original ``example_inputs`` are used for checking\n",
      "        check_tolerance (float, optional): Floating-point comparison tolerance\n",
      "            to use in the checker procedure.  This can be used to relax the\n",
      "            checker strictness in the event that results diverge numerically\n",
      "            for a known reason, such as operator fusion.\n",
      "        strict (``bool``, optional): run the tracer in a strict mode or not\n",
      "            (default: ``True``). Only turn this off when you want the tracer to\n",
      "            record your mutable container types (currently ``list``/``dict``)\n",
      "            and you are sure that the container you are using in your\n",
      "            problem is a ``constant`` structure and does not get used as\n",
      "            control flow (if, for) conditions.\n",
      "        example_kwarg_inputs (dict, optional): This parameter is a pack of keyword\n",
      "            arguments of example inputs that will be passed to the function while\n",
      "            tracing. Default: ``None``. Either this argument or ``example_inputs``\n",
      "            should be specified. The dict will be unpacking by the arguments name\n",
      "            of the traced function. If the keys of the dict don't not match with\n",
      "            the traced function's arguments name, a runtime exception will be raised.\n",
      "\n",
      "    Returns:\n",
      "        If `func` is `nn.Module` or ``forward`` of `nn.Module`, `trace` returns\n",
      "        a :class:`ScriptModule` object with a single ``forward`` method\n",
      "        containing the traced code.  The returned `ScriptModule` will\n",
      "        have the same set of sub-modules and parameters as the original\n",
      "        ``nn.Module``.  If ``func`` is a standalone function, ``trace``\n",
      "        returns `ScriptFunction`.\n",
      "\n",
      "    Example (tracing a function):\n",
      "\n",
      "    .. testcode::\n",
      "\n",
      "        import torch\n",
      "\n",
      "        def foo(x, y):\n",
      "            return 2 * x + y\n",
      "\n",
      "        # Run `foo` with the provided inputs and record the tensor operations\n",
      "        traced_foo = torch.jit.trace(foo, (torch.rand(3), torch.rand(3)))\n",
      "\n",
      "        # `traced_foo` can now be run with the TorchScript interpreter or saved\n",
      "        # and loaded in a Python-free environment\n",
      "\n",
      "    Example (tracing an existing module)::\n",
      "\n",
      "        import torch\n",
      "        import torch.nn as nn\n",
      "\n",
      "        class Net(nn.Module):\n",
      "            def __init__(self):\n",
      "                super().__init__()\n",
      "                self.conv = nn.Conv2d(1, 1, 3)\n",
      "\n",
      "            def forward(self, x):\n",
      "                return self.conv(x)\n",
      "\n",
      "        n = Net()\n",
      "        example_weight = torch.rand(1, 1, 3, 3)\n",
      "        example_forward_input = torch.rand(1, 1, 3, 3)\n",
      "\n",
      "        # Trace a specific method and construct `ScriptModule` with\n",
      "        # a single `forward` method\n",
      "        module = torch.jit.trace(n.forward, example_forward_input)\n",
      "\n",
      "        # Trace a module (implicitly traces `forward`) and construct a\n",
      "        # `ScriptModule` with a single `forward` method\n",
      "        module = torch.jit.trace(n, example_forward_input)\n",
      "\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_enabled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[0moptimize\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;34m\"`optimize` is deprecated and has no effect. \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;34m\"Use `with torch.jit.optimized_execution()` instead\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mFutureWarning\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_utils_internal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mcheck_if_torch_exportable\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mlog_torch_jit_trace_exportability\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mlog_torchscript_usage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mlog_torchscript_usage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"trace\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mtraced_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_trace_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mexample_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0moptimize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mcheck_trace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mcheck_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mcheck_tolerance\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mstrict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0m_force_outplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0m_module_class\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0m_compilation_unit\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mexample_kwarg_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0m_store_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[0mcheck_if_torch_exportable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_export\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverter\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTS2EPConverter\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_trace\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0m_convert_ts_to_export_experimental\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0m_process_jit_trace_inputs_for_export\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mtraced_func_for_export\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_trace_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mexample_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexample_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0moptimize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mcheck_trace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mcheck_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mcheck_tolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_tolerance\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mstrict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0m_force_outplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_force_outplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0m_module_class\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_module_class\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0m_compilation_unit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_compilation_unit\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mexample_kwarg_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexample_kwarg_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0m_store_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_store_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mexport_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_jit_trace_inputs_for_export\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mexample_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexample_kwarg_inputs\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mdef\u001b[0m \u001b[0m_log_exportability\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc_to_export\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexport_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexport_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexport_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mep_module\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexport_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc_to_export\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexport_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mlog_torch_jit_trace_exportability\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;34m\"trace\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexport_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ExportOutcome\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFAILED_TO_EXPORT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;32mreturn\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mexport\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mep_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mexport_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mlog_torch_jit_trace_exportability\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;34m\"trace\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexport_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ExportOutcome\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFAILED_TO_RUN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;32mreturn\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mtraced_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc_to_export\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mexport_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mlog_torch_jit_trace_exportability\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;34m\"trace\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexport_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ExportOutcome\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSUCCESS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"succeeded\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;32mreturn\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0manalyze_ts_result_with_export_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraced_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mlog_torch_jit_trace_exportability\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;34m\"trace\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexport_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ExportOutcome\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACCURACY_ERROR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;34m\"accuracy error\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;32mreturn\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mlog_torch_jit_trace_exportability\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;34m\"trace\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexport_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ExportOutcome\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSUCCESS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"succeeded\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mdef\u001b[0m \u001b[0m_direct_export_and_lower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexport_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexport_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mdef\u001b[0m \u001b[0m_convert_ts_to_export_source_to_source\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexport_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mreturn\u001b[0m \u001b[0mTS2EPConverter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexport_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# torch.jit.trace is noop when the original module is torch.jit.ScriptModule\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraced_func_for_export\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mScriptModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0m_log_exportability\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mtraced_func_for_export\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0m_direct_export_and_lower\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mexport_args\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0m_ExportType\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDIRECT_EXPORT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0m_log_exportability\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mtraced_func_for_export\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0m_convert_ts_to_export_experimental\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mexport_args\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0m_ExportType\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRACE_AND_EXPORT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0m_log_exportability\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mtraced_func_for_export\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0m_convert_ts_to_export_source_to_source\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mexport_args\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0m_ExportType\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSOURCE_TO_SOURCE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0mtraced_func\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFile:\u001b[0m      c:\\users\\xiang\\anaconda3\\lib\\site-packages\\torch\\jit\\_trace.py\n",
      "\u001b[1;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "torch.jit.trace??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracing versus Scripting for TorchScript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uP4TfihfBw9z"
   },
   "source": [
    "The traced program is generally faster than the scripted version,\n",
    "for models that are compatible with both tracing and scripting.\n",
    "\n",
    "Tracing produces a static compute graph,\n",
    "which means all control flow\n",
    "(`if`s or `for` loops)\n",
    "are effectively inlined.\n",
    "\n",
    "As written, our text recognizer has a loop with conditional breaking -- fairly typical for Transformers in autoregressive mode --\n",
    "so it isn't compatible with tracing.\n",
    "\n",
    "Furthermore, the static compute graph includes concrete choices of operations,\n",
    "e.g. specific CUDA kernels if tracing is run on the GPU.\n",
    "\n",
    "If you try to run the traced model on a system that doesn't support those kernels,\n",
    "it will crash.\n",
    "That means tracing must occur in the target deployment environment.\n",
    "\n",
    "Scripted models are much more portable, at the cost of both slower runtimes\n",
    "for a fixed hardware target and of some restrictions on how dynamic the Python code can be.\n",
    "\n",
    "We don't find the restrictions scripting places on Python code to be too onerous\n",
    "and in our experience, the performance gains are not worth the extra effort\n",
    "until the team size is larger,\n",
    "model serving hardware and strategy is more mature,\n",
    "and model release cycles are slower.\n",
    "\n",
    "For an alternative perspective that's more in favor of tracing\n",
    "and walks through how to mix-and-match scripting\n",
    "and tracing for maximum flexibility and performance, see\n",
    "[this blogpost](https://ppwwyyxx.com/blog/2022/TorchScript-Tracing-vs-Scripting/)\n",
    "from\n",
    "[Detectron2](https://ai.facebook.com/blog/-detectron2-a-pytorch-based-modular-object-detection-library-/)\n",
    "dev Yuxin Wu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cDARv-GdqtET"
   },
   "source": [
    "Choosing just one of scripting or tracing\n",
    "means we can use a high-level method\n",
    "from PyTorch Lightning,\n",
    "`to_torchscript`,\n",
    "to produce our scripted model binary\n",
    "and we don't need to touch our model code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "udvnx7sBBklY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mSignature:\u001b[0m\n",
      "\u001b[0mpl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLightningModule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_torchscript\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mfile_path\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmethod\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'script'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mexample_inputs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mScriptModule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mScriptModule\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSource:\u001b[0m   \n",
      "    \u001b[1;33m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mto_torchscript\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mfile_path\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mmethod\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"script\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mexample_inputs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mScriptModule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mScriptModule\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;34m\"\"\"By default compiles the whole model to a :class:`~torch.jit.ScriptModule`. If you want to use tracing,\n",
      "        please provided the argument ``method='trace'`` and make sure that either the `example_inputs` argument is\n",
      "        provided, or the model has :attr:`example_input_array` set. If you would like to customize the modules that are\n",
      "        scripted you should override this method. In case you want to return multiple modules, we recommend using a\n",
      "        dictionary.\n",
      "\n",
      "        Args:\n",
      "            file_path: Path where to save the torchscript. Default: None (no file saved).\n",
      "            method: Whether to use TorchScript's script or trace method. Default: 'script'\n",
      "            example_inputs: An input to be used to do tracing when method is set to 'trace'.\n",
      "              Default: None (uses :attr:`example_input_array`)\n",
      "            **kwargs: Additional arguments that will be passed to the :func:`torch.jit.script` or\n",
      "              :func:`torch.jit.trace` function.\n",
      "\n",
      "        Note:\n",
      "            - Requires the implementation of the\n",
      "              :meth:`~pytorch_lightning.core.LightningModule.forward` method.\n",
      "            - The exported script will be set to evaluation mode.\n",
      "            - It is recommended that you install the latest supported version of PyTorch\n",
      "              to use this feature without limitations. See also the :mod:`torch.jit`\n",
      "              documentation for supported features.\n",
      "\n",
      "        Example::\n",
      "\n",
      "            class SimpleModel(LightningModule):\n",
      "                def __init__(self):\n",
      "                    super().__init__()\n",
      "                    self.l1 = torch.nn.Linear(in_features=64, out_features=4)\n",
      "\n",
      "                def forward(self, x):\n",
      "                    return torch.relu(self.l1(x.view(x.size(0), -1)))\n",
      "\n",
      "            model = SimpleModel()\n",
      "            model.to_torchscript(file_path=\"model.pt\")\n",
      "\n",
      "            torch.jit.save(model.to_torchscript(\n",
      "                file_path=\"model_trace.pt\", method='trace', example_inputs=torch.randn(1, 64))\n",
      "            )\n",
      "\n",
      "        Return:\n",
      "            This LightningModule as a torchscript, regardless of whether `file_path` is\n",
      "            defined or not.\n",
      "\n",
      "        \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"script\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mwith\u001b[0m \u001b[0m_jit_is_scripting\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mtorchscript_module\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscript\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"trace\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;31m# if no example inputs are provided, try to see if model has example_input_array set\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[0mexample_inputs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexample_input_array\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[1;34m\"Choosing method=`trace` requires either `example_inputs`\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[1;34m\" or `model.example_input_array` to be defined.\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mexample_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexample_input_array\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;31m# automatically send example inputs to the right device and use trace\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mexample_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_on_before_batch_transfer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexample_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mexample_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_batch_transfer_handler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexample_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mwith\u001b[0m \u001b[0m_jit_is_scripting\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mtorchscript_module\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexample_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexample_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"The 'method' parameter only supports 'script' or 'trace', but value given was: {method}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mfs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_filesystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mwith\u001b[0m \u001b[0mfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorchscript_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mtorchscript_module\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFile:\u001b[0m      c:\\users\\xiang\\anaconda3\\lib\\site-packages\\pytorch_lightning\\core\\module.py\n",
      "\u001b[1;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "\n",
    "pl.LightningModule.to_torchscript??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iXftpJBizrM6"
   },
   "source": [
    "## Alternatives to TorchScript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QvFh_SW8v4p6"
   },
   "source": [
    "Though it has some sharp edges,\n",
    "TorchScript is a relatively easy to use tool\n",
    "for compiling neural networks written in PyTorch.\n",
    "\n",
    "If you're willing to tolerate more sharp edges,\n",
    "e.g. limited support for certain ops\n",
    "and a higher risk of subtle differences in behavior, the\n",
    "[Open Neural Network eXchange](https://onnx.ai/)\n",
    "format, ONNX, is a compilation target for\n",
    "[a wide variety of DNN libraries](https://onnx.ai/supported-tools.html),\n",
    "from `sklearn` and MATLAB\n",
    "to PyTorch and Hugging Face.\n",
    "\n",
    "A high-level utility for conversion to ONNX is also included\n",
    "in PyTorch Lightning, `pl.LightningModule.to_onnx`.\n",
    "\n",
    "Because it is framework agnostic,\n",
    "there's more and more varied tooling around ONNX,\n",
    "and it has smoother paths to\n",
    "compilation targets that can run DNNs\n",
    "at the highest possible speeds,\n",
    "like\n",
    "[NVIDIA's TensorRT](https://developer.nvidia.com/tensorrt)\n",
    "or\n",
    "[Apache TVM](https://tvm.apache.org/2017/08/17/tvm-release-announcement).\n",
    "\n",
    "TensorRT is the model format used in the\n",
    "[Triton Inference Server](https://github.com/triton-inference-server/server),\n",
    "a sort of \"kubernetes for GPU-accelerated DNNs\"\n",
    "that is, as of 2022,\n",
    "the state of the art in running deep networks\n",
    "at maximum throughput on server-grade GPUs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "36dKPerevkhZ"
   },
   "source": [
    "## A simple script for compiling and staging models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "93pc-NLrBR1A"
   },
   "source": [
    "To recap, our model staging workflow,\n",
    "which does the hand-off between training and production, looks like this:\n",
    "\n",
    "1. Get model weights and hyperparameters\n",
    "from a tracked training run in W&B's cloud storage.\n",
    "2. Reload the model as a `LightningModule` using those weights and hyperparameters.\n",
    "3. Call `to_torchscript` on it.\n",
    "4. Save that result to W&B's cloud storage.\n",
    "\n",
    "We provide a simple script to implement this process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "gqgiWO0tFktU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: stage_model.py [-h] [--fetch] [--entity ENTITY]\n",
      "                      [--from_project FROM_PROJECT] [--to_project TO_PROJECT]\n",
      "                      [--run RUN] [--ckpt_alias CKPT_ALIAS]\n",
      "                      [--staged_model_name STAGED_MODEL_NAME]\n",
      "\n",
      "Stages a model for use in production. If based on a checkpoint, the model is\n",
      "converted to torchscript, saved locally, and uploaded to W&B. If based on a\n",
      "model that is already converted and uploaded, the model file is downloaded\n",
      "locally. For details on how the W&B artifacts backing the checkpoints and\n",
      "models are handled, see the documenation for stage_model.find_artifact.\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --fetch               If provided, check ENTITY/FROM_PROJECT for an artifact\n",
      "                        with the provided STAGED_MODEL_NAME and download its\n",
      "                        latest version to D:\\RL_Finance\\MLops\\fslab\\lab07\\text\n",
      "                        _recognizer\\artifacts/STAGED_MODEL_NAME.\n",
      "  --entity ENTITY       Entity from which to download the checkpoint. Note\n",
      "                        that checkpoints are always uploaded to the logged-in\n",
      "                        wandb entity. Pass the value 'DEFAULT' to also\n",
      "                        download from default entity, which is currently\n",
      "                        xiangyexu-university-of-waterloo.\n",
      "  --from_project FROM_PROJECT\n",
      "                        Project from which to download the checkpoint. Default\n",
      "                        is fsdl-text-recognizer-2022-training\n",
      "  --to_project TO_PROJECT\n",
      "                        Project to which to upload the compiled model. Default\n",
      "                        is fsdl-text-recognizer-2022-training.\n",
      "  --run RUN             Optionally, the name of a run to check for an artifact\n",
      "                        of type model that has the provided CKPT_ALIAS.\n",
      "                        Default is None.\n",
      "  --ckpt_alias CKPT_ALIAS\n",
      "                        Alias that identifies which model checkpoint should be\n",
      "                        staged.The artifact's alias can be set manually or\n",
      "                        programmatically elsewhere. Default is 'best'.\n",
      "  --staged_model_name STAGED_MODEL_NAME\n",
      "                        Name to give the staged model artifact. Default is\n",
      "                        'paragraph-text-recognizer'.\n"
     ]
    }
   ],
   "source": [
    "%run training/stage_model.py --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i4qEqMRkFsd4"
   },
   "source": [
    "Here in this notebook,\n",
    "rather than training or scripting a model ourselves,\n",
    "we'll just `--fetch`\n",
    "an already trained and scripted model binary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m      2\u001b[0m LOG_DIR \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogs\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m PROJECT_ROOT \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;18;43m__file__\u001b[39;49m)\u001b[38;5;241m.\u001b[39mresolve()\u001b[38;5;241m.\u001b[39mparents[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      4\u001b[0m PROJECT_ROOT\n",
      "\u001b[1;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "PROJECT_ROOT = Path(__file__).resolve().parents[1]\n",
    "PROJECT_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training import stage_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('D:/RL_Finance/MLops/fslab/lab07/text_recognizer/artifacts')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "PROJECT_ROOT = Path(stage_model.__file__).resolve().parents[1]\n",
    "PROD_STAGING_ROOT = PROJECT_ROOT / \"text_recognizer\" / \"artifacts\"\n",
    "PROD_STAGING_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xiangyexu-university-of-waterloo'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "\n",
    "api = wandb.Api()\n",
    "DEFAULT_ENTITY = api.default_entity\n",
    "DEFAULT_ENTITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cfrye59/fsdl-text-recognizer-2021-training/paragraph-text-recognizer:latest'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"cfrye59/fsdl-text-recognizer-2021-training/paragraph-text-recognizer:latest\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "c2wfjLmRDwrH"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact paragraph-text-recognizer:latest, 416.00MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:41.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using artifact cfrye59/fsdl-text-recognizer-2021-training/paragraph-text-recognizer:latest\n",
      "View at URL: https://wandb.ai/cfrye59/fsdl-text-recognizer-2021-training/artifacts/prod-ready/paragraph-text-recognizer/latest\n",
      "Logged by glad-glitter-429 -- fsdl-text-recognizer-2021-training/cfrye59/2aaexmgd\n",
      "View at URL: https://wandb.ai/cfrye59/fsdl-text-recognizer-2021-training/runs/2aaexmgd\n"
     ]
    }
   ],
   "source": [
    "%run training/stage_model.py --fetch --entity=cfrye59 --from_project=fsdl-text-recognizer-2021-training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I0uNnvjkCZzX"
   },
   "source": [
    "Note that we can use the metadata of the staged model\n",
    "to find the training run that generated the model weights.\n",
    "It requires two graph hops:\n",
    "find the run that created the staged TorchScript model\n",
    "then in that run,\n",
    "find the model checkpoint artifact\n",
    "and look for the run that created it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E9zJg44hCjRv"
   },
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "\n",
    "\n",
    "staged_model_url = \"https://wandb.ai/cfrye59/fsdl-text-recognizer-2021-training/artifacts/prod-ready/paragraph-text-recognizer/3e07efa34aec61999c5a/overview\"\n",
    "\n",
    "IFrame(staged_model_url, width=\"100%\", height=720)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we're deploying our first model,\n",
    "this doesn't feel that important --\n",
    "it's easy enough to find the training runs\n",
    "we've executed and connect them to the model in production.\n",
    "\n",
    "But as we train and release more models,\n",
    "this information will become harder to find\n",
    "and automation and API access will become more important.\n",
    "\n",
    "This will be especially true if we adopt more sophisticated rollout strategies,\n",
    "like A/B testing or canarying,\n",
    "as the application matures.\n",
    "\n",
    "Our system here is not robust enough to be Enterprise Grade --\n",
    "marking models as \"in production\" is manual\n",
    "and there are no access control planes built in --\n",
    "but at least the information is preserved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running our more portable model via a CLI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X7d2WHSCHHHP"
   },
   "source": [
    "Now that our TorchScript model binary file is present,\n",
    "we can spin up our text recognizer\n",
    "with much less code.\n",
    "\n",
    "We just need a compatible version of PyTorch\n",
    "and methods to convert\n",
    "our generic data types\n",
    "(images, strings)\n",
    "to and from PyTorch `Tensor`s.\n",
    "\n",
    "We can put all this together in\n",
    "a single light-weight object,\n",
    "the `ParagraphTextRecognizer` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ZGXZep-nDiDk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mInit signature:\u001b[0m \u001b[0mParagraphTextRecognizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSource:\u001b[0m        \n",
      "\u001b[1;32mclass\u001b[0m \u001b[0mParagraphTextRecognizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Recognizes a paragraph of text in an image.\"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mmodel_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSTAGED_MODEL_DIRNAME\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mMODEL_FILE\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmapping\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmapping\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mignore_tokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mignore_tokens\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParagraphStem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;34m\"\"\"Predict/infer text in input image (which can be a file path or url).\"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mimage_pil\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mimage_pil\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_image_pil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrayscale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mimage_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_pil\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mpred_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_y_label_to_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmapping\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_tokens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mignore_tokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mpred_str\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFile:\u001b[0m           d:\\rl_finance\\mlops\\fslab\\lab07\\text_recognizer\\paragraph_text_recognizer.py\n",
      "\u001b[1;31mType:\u001b[0m           type\n",
      "\u001b[1;31mSubclasses:\u001b[0m     "
     ]
    }
   ],
   "source": [
    "from text_recognizer.paragraph_text_recognizer import ParagraphTextRecognizer\n",
    "\n",
    "\n",
    "ParagraphTextRecognizer??\n",
    "\n",
    "ptr = ParagraphTextRecognizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uwVo6BoeGmTW"
   },
   "source": [
    "And from there,\n",
    "we can start running on images\n",
    "and inferring the text that they contain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "CMZlfIoeG3hy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And, since this is election year in West\n",
      "Germany, Dr. Adenauer is in a tough\n",
      "spot. Joyce Egginton cables: President\n",
      "Kennedy at his Washington Press con-\n",
      "ference admitted he did not know\n",
      "whether America was lagging behind\n",
      "Russia in missile power. He said he\n",
      "was waiting for his senior military\n",
      "aides to come up with the answer on\n",
      "February 20.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "example_input = \"text_recognizer/tests/support/paragraphs/a01-077.png\"\n",
    "\n",
    "print(ptr.predict(example_input))\n",
    "Image(example_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6AHq1TH44Jq"
   },
   "source": [
    "As usual,\n",
    "we write our Python code\n",
    "so that it can be imported as a module\n",
    "and run in a Jupyter notebook,\n",
    "for documentation and experimentation,\n",
    "and we make it executable as a script\n",
    "for easier automation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "igY7sd8eGGI3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And, since this is election year in West\n",
      "Germany, Dr. Adenauer is in a tough\n",
      "spot. Joyce Egginton cables: President\n",
      "Kennedy at his Washington Press con-\n",
      "ference admitted he did not know\n",
      "whether America was lagging behind\n",
      "Russia in missile power. He said he\n",
      "was waiting for his senior military\n",
      "aides to come up with the answer on\n",
      "February 20.\n"
     ]
    }
   ],
   "source": [
    "## %run text_recognizer/paragraph_text_recognizer.py --help\n",
    "\n",
    "\n",
    "## Here we use directly the script to produce result\n",
    "%run text_recognizer/paragraph_text_recognizer.py {example_input}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MvYmSN0rE2BP"
   },
   "source": [
    "Notice that the `filename` here can be a local file, a URL, or even a cloud storage URI.\n",
    "\n",
    "Rather than writing the logic for handling these different cases,\n",
    "we use the\n",
    "[`smart_open` library](https://pypi.org/project/smart-open/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3WQ-P16VC94R"
   },
   "source": [
    "## Testing our model development pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0kVq2iBJDZH5"
   },
   "source": [
    "Creating models is _the_ critical function of our code base,\n",
    "so it's important that we test it,\n",
    "at the very least with \"smoke tests\" that let us know\n",
    "if the code is completely broken.\n",
    "\n",
    "Right now we have tests for data loading and model training,\n",
    "but no tests for end-to-end model development,\n",
    "which combines data loading, model training, and model compilation.\n",
    "\n",
    "So we add a simple model development test\n",
    "that trains a model for a very small number of steps\n",
    "and then runs our staging script.\n",
    "\n",
    "This model development test script returns an error code (`exit 1`) if the process of\n",
    "building a model fails (`\"$FAILURE\" = true`).\n",
    "\n",
    "We use\n",
    "[the `||` operator](https://www.unix.com/shell-programming-and-scripting/42417-what-does-mean-double-pipe.html)\n",
    "to set the `FAILURE` variable to `true` if any of the key commands in model development fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "XPkwFxklDA5V",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'cat' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!cat training/tests/test_model_development.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "set -uo pipefail\n",
      "set +e\n",
      "\n",
      "FAILURE=false\n",
      "\n",
      "CI=\"${CI:-false}\"\n",
      "if [ \"$CI\" = false ]; then\n",
      "  export WANDB_PROJECT=\"fsdl-testing-2022\"\n",
      "else\n",
      "  export WANDB_PROJECT=\"fsdl-testing-2022-ci\"\n",
      "fi\n",
      "\n",
      "echo \"training smaller version of real model class on real data\"\n",
      "python training/run_experiment.py --data_class=IAMParagraphs --model_class=ResnetTransformer --loss=transformer \\\n",
      "  --tf_dim 4 --tf_fc_dim 2 --tf_layers 2 --tf_nhead 2 --batch_size 2 --lr 0.0001 \\\n",
      "  --limit_train_batches 1 --limit_val_batches 1 --limit_test_batches 1 --num_sanity_val_steps 0 \\\n",
      "  --num_workers 1 --wandb || FAILURE=true\n",
      "\n",
      "TRAIN_RUN=$(find ./training/logs/wandb/latest-run/* | grep -Eo \"run-([[:alnum:]])+\\.wandb\" | sed -e \"s/^run-//\" -e \"s/\\.wandb//\")\n",
      "\n",
      "echo \"staging trained model from run $TRAIN_RUN\"\n",
      "python training/stage_model.py --entity DEFAULT --run \"$TRAIN_RUN\" --staged_model_name test-dummy --ckpt_alias latest --to_project \"$WANDB_PROJECT\" --from_project \"$WANDB_PROJECT\" || FAILURE=true\n",
      "\n",
      "echo \"fetching staged model\"\n",
      "python training/stage_model.py --entity DEFAULT --fetch --from_project $WANDB_PROJECT --staged_model_name test-dummy || FAILURE=true\n",
      "STAGE_RUN=$(find ./training/logs/wandb/latest-run/* | grep -Eo \"run-([[:alnum:]])+\\.wandb\" | sed -e \"s/^run-//\" -e \"s/\\.wandb//\")\n",
      "\n",
      "if [ \"$FAILURE\" = true ]; then\n",
      "  echo \"Model development test failed\"\n",
      "  echo \"cleaning up local files\"\n",
      "  rm -rf text_recognizer/artifacts/test-dummy\n",
      "  echo \"leaving remote files in place\"\n",
      "  exit 1\n",
      "fi\n",
      "echo \"cleaning up local and remote files\"\n",
      "rm -rf text_recognizer/artifacts/test-dummy\n",
      "python training/cleanup_artifacts.py --entity DEFAULT --project \"$WANDB_PROJECT\" \\\n",
      "  --run_ids \"$TRAIN_RUN\" \"$STAGE_RUN\" --all -v\n",
      "# note: if $TRAIN_RUN and $STAGE_RUN are not set, this will fail.\n",
      "#  that's good because it avoids all artifacts from the project being deleted due to the --all.\n",
      "echo \"Model development test passed\"\n",
      "exit 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"training/tests/test_model_development.sh\", \"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pQ21iRDqFvxj"
   },
   "source": [
    "As a next step to improve the coverage of this test,\n",
    "we might compare the model's outputs\n",
    "on the same inputs before and after compilation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hyXZhgqEvfe9"
   },
   "source": [
    "### Cleaning up artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l22DqhC4GIJT"
   },
   "source": [
    "The final few lines of the testing script mention\n",
    "\"`selecting for deletion`\" some artifacts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EbIW5okFGQv7"
   },
   "source": [
    "As we incorporate more of our code into testing\n",
    "and develop more models,\n",
    "the amount of information we are storing on W&B increases.\n",
    "\n",
    "We're already uploading model checkpoints, several gigabytes per model training run,\n",
    "and now we're also looking at uploading several hundred megabytes\n",
    "of model data per execution of our test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T7aBCfpuJVJV"
   },
   "source": [
    "Artifact storage is free up to 100GB,\n",
    "but storing more requires a paid account.\n",
    "\n",
    "That means it literally pays to clean up after ourselves.\n",
    "\n",
    "We use a very simple script to select certain artifacts for deletion.\n",
    " \n",
    ">  **Don't use this untested demonstration script in important environments!** \n",
    "We include options for `-v`erbose output and a `--dryrun` mode,\n",
    "which are both critical for destructive actions that have access\n",
    "to model weights that might cost $1000s to produce.\n",
    "\n",
    "See the `--help` below for more on cleaning up artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "8hSqzRplITVB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: cleanup_artifacts.py [-h] [--entity ENTITY] [--project PROJECT]\n",
      "                            [--run_ids [RUN_IDS ...]]\n",
      "                            [--run_name_res [RUN_NAME_REGEX ...]]\n",
      "                            [--all | --no-alias | --aliases [ALIASES ...]]\n",
      "                            [-v] [--dryrun]\n",
      "\n",
      "Removes artifacts from projects and runs. Artifacts are binary files that we\n",
      "want to track and version but don't want to include in git, generally because\n",
      "they are too large, because they don't have meaningful diffs, or because they\n",
      "change more quickly than code. During development, we often generate artifacts\n",
      "that we don't really need, e.g. model weights for an overfitting test run.\n",
      "Space on artifact storage is generally very large, but it is limited, so we\n",
      "should occasionally delete unneeded artifacts to reclaim some of that space.\n",
      "For usage help, run python training/cleanup_artifacts.py --help\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --entity ENTITY       The entity from which to remove artifacts. Provide the\n",
      "                        value DEFAULT to use the default WANDB_ENTITY, which\n",
      "                        is currently xiangyexu-university-of-waterloo.\n",
      "  --project PROJECT     The project from which to remove artifacts. Default is\n",
      "                        fsdl-text-recognizer-2022-training\n",
      "  --run_ids [RUN_IDS ...]\n",
      "                        One or more run IDs from which to remove artifacts.\n",
      "                        Default is None.\n",
      "  --run_name_res [RUN_NAME_REGEX ...]\n",
      "                        One or more regular expressions to use to select runs\n",
      "                        (by display name) from which to remove artifacts. See\n",
      "                        wandb.Api.runs documentation for details on the\n",
      "                        syntax. Beware that this is a footgun and consider\n",
      "                        using interactively with --dryrun and -v. Default is\n",
      "                        None.\n",
      "  --all                 Delete all artifacts from selected runs.\n",
      "  --no-alias            Delete all artifacts without an alias from selected\n",
      "                        runs.\n",
      "  --aliases [ALIASES ...]\n",
      "                        Delete artifacts that have any of the aliases from the\n",
      "                        provided list from selected runs.\n",
      "  -v                    Display information about targeted entities, projects,\n",
      "                        runs, and artifacts.\n",
      "  --dryrun              Select artifacts without deleting them and display\n",
      "                        which artifacts were selected.\n"
     ]
    }
   ],
   "source": [
    "%run training/cleanup_artifacts.py --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BfB38ywTJDMT"
   },
   "source": [
    "## Tuning inference performance on CPU and GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zau0MRr1FPw-"
   },
   "source": [
    "Apart from compilation to TorchScript,\n",
    "the biggest difference for running the model in production\n",
    "is that now all of our operations occur on the CPU.\n",
    "\n",
    "This is a surprising feature of DNN deployment\n",
    "that's worth thinking about in detail.\n",
    "\n",
    "Why isn't it a given that deep network inference\n",
    "runs on GPUs, when that's so critical for deep network training?\n",
    "\n",
    "First,\n",
    "not many web applications use GPUs,\n",
    "so there aren't nearly as many good tools and techniques\n",
    "for deplyoing GPU-backed services.\n",
    "\n",
    "But there's another, deeper reason:\n",
    "GPUs are not as easy to run efficiently\n",
    "during inference as they are in training.\n",
    "\n",
    "In training,\n",
    "we use static or synthetic datasets\n",
    "and our training code is in charge\n",
    "of the query patterns.\n",
    "\n",
    "In particular,\n",
    "we can request exactly as many inputs\n",
    "as we want to produce a batch\n",
    "that makes optimal use\n",
    "of our expensive GPUs.\n",
    "\n",
    "In production, requests arrive independently,\n",
    "according to the whims of our users.\n",
    "\n",
    "This makes batching challenging,\n",
    "and by far the simplest service architecture\n",
    "just runs on each request as it arrives.\n",
    "\n",
    "But that tanks GPU utilization.\n",
    "\n",
    "GPUs are highly parallel computers,\n",
    "and batch is the easiest dimension to parallelize on --\n",
    "for example, we load the model weights into memory once,\n",
    "use them, and then release the memory.\n",
    "\n",
    "The cell below\n",
    "compares two traces\n",
    "for a GPU-accelerated\n",
    "Text Recognizer model running\n",
    "on a single input and on a batch.\n",
    "\n",
    "For a simple summary,\n",
    "you can compare the two profiles in TensorBoard\n",
    "([batch size 1 here](https://wandb.ai/cfrye59/fsdl-text-recognizer-2022-labs-lab05_training/runs/1vj48h6j/tensorboard?workspace=user-cfrye59),\n",
    "[batch size 16 here](https://wandb.ai/cfrye59/fsdl-text-recognizer-2022-training/runs/67j1qxws/tensorboard?workspace=user-cfrye59)).\n",
    "\n",
    "GPU utilization,\n",
    "our baseline metric for model performance,\n",
    "is under 50% with batch size 1,\n",
    "as compared to >90% with batch size 16,\n",
    "which fills up GPU RAM.\n",
    "\n",
    "You can also look through the traces for more details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B_NZPLWa-ZVP"
   },
   "outputs": [],
   "source": [
    "trace_comparison_url = \"https://wandb.ai/cfrye59/fsdl-text-recognizer-2022-labs-lab05_training/reports/Trace-Comparison-Batch-Size-16-vs-1--VmlldzoyNTg2MTU4\"\n",
    "\n",
    "print(trace_comparison_url)\n",
    "IFrame(src=trace_comparison_url, width=\"100%\", height=frame_height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_6_U1OyU-Vsi"
   },
   "source": [
    "But performance during inference is not as simple \n",
    "as just \"maximize GPU utilization\".\n",
    "\n",
    "In particular, throughput for the GPU with batch size 16\n",
    "is over 2x better,\n",
    "one example per 8 ms vs\n",
    "one example per 40 ms,\n",
    "but latency is much worse.\n",
    "\n",
    "It takes 140ms to complete the batch of size 16.\n",
    "In the intervening time no examples are completed,\n",
    "and all 16 users are waiting on a response.\n",
    "\n",
    "For comparison,\n",
    "running one example at a time\n",
    "would get the first user's result\n",
    "in just 40 ms,\n",
    "but the total processing time for all 16 examples would be\n",
    "640 ms.\n",
    "\n",
    "For user experience, latency is critical,\n",
    "but for making the most efficient use of hardware,\n",
    "throughput is generally more important.\n",
    "\n",
    "During training, we care much less about latency\n",
    "and much more about computing gradients as fast as possible,\n",
    "so we aim for larger batch sizes.\n",
    "\n",
    "Because of the need for efficient use of hardware,\n",
    "running on single inputs isn't always feasible.\n",
    "\n",
    "The usual solution is to run a queue,\n",
    "which collects up enough requests for a batch.\n",
    "\n",
    "One of the easiest ways to do this as of writing in September 2022 is to use\n",
    "[`cog` by Replicate](https://github.com/replicate/cog),\n",
    "which both solves difficult issues with containerizing\n",
    "models with GPU acceleration \n",
    "and includes, as a beta feature, a built-in Redis queue\n",
    "for batching requests and responses.\n",
    "\n",
    "But note that we can't just run a queue that waits for,\n",
    "say, 16 user requests\n",
    "to build up, then runs them all.\n",
    "If 15 requests come in at once,\n",
    "but then no requests come for an hour,\n",
    "all 15 users will be waiting for an hour\n",
    "for their responses --\n",
    "much worse than just waiting a few hundred extra milliseconds!\n",
    "\n",
    "We need to make sure the queue flushes after a certain amount of time,\n",
    "regardless of how many requests it has received,\n",
    "complicating our implementation.\n",
    "\n",
    "Running single inputs on GPUs\n",
    "and running a naive queue\n",
    "are two different ways it's easy to accidentally tank latency\n",
    "while pursuing efficiency,\n",
    "at least for some fraction of cases.\n",
    "\n",
    "So we stick with CPU inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "te-CYidTslPo"
   },
   "source": [
    "# Building a simple model UI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4kGXwQvjJq32"
   },
   "source": [
    "With compilation,\n",
    "we've moved from a model that can only run\n",
    "in a very special environment\n",
    "and with lots of support code\n",
    "into something lightweight\n",
    "that runs with a simple CLI.\n",
    "\n",
    "If we want users to send data to our model\n",
    "and get useful predictions out,\n",
    "we need to create a UI.\n",
    "\n",
    "But a CLI is not a UI --\n",
    "it's at best the foundation out of which a UI is built.\n",
    "\n",
    "This is not just a concern once the model is finished:\n",
    "a UI is an incredible tool for model debugging.\n",
    "\n",
    "It's hard to overstate the difference between\n",
    "a static, CLI or code-writing workflow\n",
    "for sending information to a model\n",
    "and an interactive interface.\n",
    "\n",
    "When your model is easily accessible on a mobile phone,\n",
    "when you can copy-paste text from elsewhere on your machine or the internet,\n",
    "or when you can upload arbitrary files,\n",
    "the whole range of possible inputs becomes clear\n",
    "in a way that's very hard to replicate with fixed data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S163btePLB1K"
   },
   "source": [
    "Unfortunately, creating a GUI from scratch is not easy,\n",
    "especially in Python.\n",
    "\n",
    "The best tool for GUIs is the browser,\n",
    "but the lingua franca of the browser\n",
    "is JavaScript\n",
    "([for now](https://webassembly.org/)).\n",
    "\n",
    "As full stack deep learning engineers,\n",
    "we're already writing Python with C/C++ acceleration,\n",
    "we're gluing scripts together with Bash,\n",
    "and we need to know enough SQL to talk to databases.\n",
    "\n",
    "Do we now need to learn front-end web development too?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oSeBo0MzL0H9"
   },
   "source": [
    "In the long term, it's a good investment,\n",
    "and we recommend\n",
    "[The Odin Project](https://www.theodinproject.com/),\n",
    "a free online course and community for learning web development.\n",
    "\n",
    "Their\n",
    "[Foundations course](https://www.theodinproject.com/paths/foundations/courses/foundations#html-foundations),\n",
    "starting from HTML foundations and proceeding\n",
    "through basic CSS\n",
    "and JavaScript,\n",
    "is a great way to dip your toes in\n",
    "and learn enough about building websites and UIs\n",
    "in the browser to be dangerous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q-7pJcsCL_84"
   },
   "source": [
    "In the short term,\n",
    "we write our frontends in Python libraries\n",
    "that effectively write the frontend JavaScript/CSS/HTML\n",
    "for us.\n",
    "\n",
    "For the past few years,\n",
    "[Streamlit](https://streamlit.io/)\n",
    "has been a popular choice for the busy Python data scientist.\n",
    "\n",
    "It remains a solid choice,\n",
    "and tooling for building complex apps with Streamlit is more mature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xey5gzr5tV51"
   },
   "source": [
    "We use the\n",
    "[`gradio` library](https://gradio.app/),\n",
    "which includes a simple API for wrapping\n",
    "a single Python function into a frontend\n",
    "in addition to a less mature, lower-level API\n",
    "for building apps more flexibly.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2XvUr7irMHQ6"
   },
   "source": [
    "This iteration of the FSDL codebase\n",
    "includes a new module,\n",
    "`app_gradio`,\n",
    "that makes a simple UI for the Text Recognizer\n",
    "using `gradio`.\n",
    "\n",
    "The core component is a script,\n",
    "`app_gradio/app.py`,\n",
    "that can be used to spin up our model and UI\n",
    "from the command line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "w2Ra8ot292XX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: app.py [-h] [--model_url MODEL_URL] [--port PORT]\n",
      "\n",
      "Provide an image of handwritten text and get back out a string!\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --model_url MODEL_URL\n",
      "                        Identifies a URL to which to send image data. Data is\n",
      "                        base64-encoded, converted to a utf-8 string, and then\n",
      "                        set via a POST request as JSON with the key 'image'.\n",
      "                        Default is None, which instead sends the data to a\n",
      "                        model running locally.\n",
      "  --port PORT           Port on which to expose this server. Default is 11700.\n"
     ]
    }
   ],
   "source": [
    "%run app_gradio/app.py --help\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J9bP3zFo9_YY"
   },
   "source": [
    "But one very nice feature of `gradio`\n",
    "is that it is designed to run as easily\n",
    "from the notebook as from the command line.\n",
    "\n",
    "Let's import the contents of `app.py`\n",
    "and take a look,\n",
    "then launch our UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_recognizer.paragraph_text_recognizer import ParagraphTextRecognizer\n",
    "\n",
    "ptr = ParagraphTextRecognizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "vryi5r6gDj6D"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "INFO:httpx:HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "BlockContext.__init__() got an unexpected keyword argument 'enable_queue'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mapp_gradio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m app\n\u001b[1;32m----> 2\u001b[0m frontend \u001b[38;5;241m=\u001b[39m \u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_frontend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mptr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\RL_Finance\\MLops\\fslab\\lab07\\app_gradio\\app.py:56\u001b[0m, in \u001b[0;36mmake_frontend\u001b[1;34m(fn)\u001b[0m\n\u001b[0;32m     53\u001b[0m readme \u001b[38;5;241m=\u001b[39m _load_readme(with_logging\u001b[38;5;241m=\u001b[39mallow_flagging \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmanual\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# build a basic browser interface to a Python function\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m frontend \u001b[38;5;241m=\u001b[39m \u001b[43mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInterface\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# which Python function are we interacting with?\u001b[39;49;00m\n\u001b[0;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomponents\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTextbox\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# what output widgets does it need? the default text widget\u001b[39;49;00m\n\u001b[0;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# what input widgets does it need? we configure an image widget\u001b[39;49;00m\n\u001b[0;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomponents\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mImage\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpil\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHandwritten Text\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtitle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m Text Recognizer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# what should we display at the top of the page?\u001b[39;49;00m\n\u001b[0;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;18;43m__doc__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# what should we display just above the interface?\u001b[39;49;00m\n\u001b[0;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43marticle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreadme\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# what long-form content should we display below the interface?\u001b[39;49;00m\n\u001b[0;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexamples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# which potential inputs should we provide?\u001b[39;49;00m\n\u001b[0;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# should we cache those inputs for faster inference? slows down start\u001b[39;49;00m\n\u001b[0;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_flagging\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_flagging\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# should we show users the option to \"flag\" outputs?\u001b[39;49;00m\n\u001b[0;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_queue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frontend\n",
      "File \u001b[1;32mc:\\Users\\xiang\\anaconda3\\lib\\site-packages\\gradio\\interface.py:190\u001b[0m, in \u001b[0;36mInterface.__init__\u001b[1;34m(self, fn, inputs, outputs, examples, cache_examples, cache_mode, examples_per_page, example_labels, live, title, description, article, theme, flagging_mode, flagging_options, flagging_dir, flagging_callback, analytics_enabled, batch, max_batch_size, api_name, _api_mode, allow_duplication, concurrency_limit, css, css_paths, js, head, head_paths, additional_inputs, additional_inputs_accordion, submit_btn, stop_btn, clear_btn, delete_cache, show_progress, fill_width, allow_flagging, time_limit, stream_every, **kwargs)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    100\u001b[0m     fn: Callable,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    148\u001b[0m ):\n\u001b[0;32m    149\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;124;03m    Parameters:\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;124;03m        fn: the function to wrap an interface around. Often a machine learning model's prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;124;03m        stream_every: The latency (in seconds) at which stream chunks are sent to the backend. Defaults to 0.5 seconds. Parameter only used for streaming images or audio if the interface is live and the input components are set to \"streaming=True\".\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 190\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    191\u001b[0m         analytics_enabled\u001b[38;5;241m=\u001b[39manalytics_enabled,\n\u001b[0;32m    192\u001b[0m         mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minterface\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    193\u001b[0m         title\u001b[38;5;241m=\u001b[39mtitle \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGradio\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    194\u001b[0m         theme\u001b[38;5;241m=\u001b[39mtheme,\n\u001b[0;32m    195\u001b[0m         css\u001b[38;5;241m=\u001b[39mcss,\n\u001b[0;32m    196\u001b[0m         css_paths\u001b[38;5;241m=\u001b[39mcss_paths,\n\u001b[0;32m    197\u001b[0m         js\u001b[38;5;241m=\u001b[39mjs,\n\u001b[0;32m    198\u001b[0m         head\u001b[38;5;241m=\u001b[39mhead,\n\u001b[0;32m    199\u001b[0m         head_paths\u001b[38;5;241m=\u001b[39mhead_paths,\n\u001b[0;32m    200\u001b[0m         delete_cache\u001b[38;5;241m=\u001b[39mdelete_cache,\n\u001b[0;32m    201\u001b[0m         fill_width\u001b[38;5;241m=\u001b[39mfill_width,\n\u001b[0;32m    202\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    203\u001b[0m     )\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_limit \u001b[38;5;241m=\u001b[39m time_limit\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_every \u001b[38;5;241m=\u001b[39m stream_every\n",
      "File \u001b[1;32mc:\\Users\\xiang\\anaconda3\\lib\\site-packages\\gradio\\blocks.py:1157\u001b[0m, in \u001b[0;36mBlocks.__init__\u001b[1;34m(self, theme, analytics_enabled, mode, title, css, css_paths, js, head, head_paths, fill_height, fill_width, delete_cache, **kwargs)\u001b[0m\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menable_monitoring: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1156\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_config \u001b[38;5;241m=\u001b[39m BlocksConfig(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m-> 1157\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(render\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1159\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m=\u001b[39m mode\n\u001b[0;32m   1160\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_running \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: BlockContext.__init__() got an unexpected keyword argument 'enable_queue'"
     ]
    }
   ],
   "source": [
    "from app_gradio import app\n",
    "frontend = app.make_frontend(ptr.predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use `gradio`'s high-level API, `gr.Interface`,\n",
    "to build a UI by wrapping our `ptr.predict` function,\n",
    "defining its inputs\n",
    "(an `Image`)\n",
    "and outputs\n",
    "(a `TextBox`),\n",
    "and specifying some formatting\n",
    "and styling choices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m0HxOukBNn13"
   },
   "source": [
    "\n",
    "\n",
    "We can spin up our UI with the `.launch` method,\n",
    "and now we can interact\n",
    "with the model from inside the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "XoVFtGbuDlTL"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/startup-events \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: HEAD http://127.0.0.1:7860/ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.gradio.app/v3/tunnel-request \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on public URL: https://d8f48ef7be822a0319.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: HEAD https://d8f48ef7be822a0319.gradio.live \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://d8f48ef7be822a0319.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frontend.launch(share=True, width=\"100%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "okcoAW7sM13h"
   },
   "source": [
    "For 72 hours, we can also access the model over the public internet\n",
    "using a URL provided by `gradio`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "x5pEhMECNIT6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://d8f48ef7be822a0319.gradio.live\n"
     ]
    }
   ],
   "source": [
    "print(frontend.share_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LYfi-lZqNNZd"
   },
   "source": [
    "You can point your browser to that URL\n",
    "to see what the model looks like as a full-fledged web application,\n",
    "instead of a widget inside the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2L5uZCJlOGi4"
   },
   "source": [
    "In addition to this UI,\n",
    "`gradio` also creates a simple REST API,\n",
    "so we can make requests\n",
    "from outside the browser,\n",
    "programmatically,\n",
    "and get responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "XOngmAWvQnqg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: API_URL=https://d8f48ef7be822a0319.gradio.live/api\n"
     ]
    }
   ],
   "source": [
    "%env API_URL={frontend.share_url + \"/api\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cj6XSur7Nlzf"
   },
   "source": [
    "We can see the details of the API by clicking\n",
    "\"view api\" at the bottom of the Gradio interface.\n",
    "\n",
    "In particular,\n",
    "we can see that the API expects image data in\n",
    "[base64 format](https://developer.mozilla.org/en-US/docs/Glossary/Base64),\n",
    "which encodes binary data as ASCII text\n",
    "so that it can be sent over interfaces that expect ASCII text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "igeFyT84WqqG"
   },
   "source": [
    "The line below encodes an image with the `base64` utility,\n",
    "packages it into the appropriate JSON format\n",
    "and uses `echo` to pipe it into a `curl` command.\n",
    "\n",
    "`curl` can be used to make requests to web services at URLs\n",
    "-- here `${API_URL}/predict` --\n",
    "of specific types\n",
    "-- here `POST` --\n",
    "that include `-d`ata\n",
    "and `-H`eaders identifying the format of the data.\n",
    "\n",
    "The response is returned as\n",
    "[string-formatted JSON](https://developer.mozilla.org/en-US/docs/Learn/JavaScript/Objects/JSON)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "_nmRbYQCOd3t"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"detail\":\"Not Found\"}'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response, = ! \\\n",
    "  (echo -n '{ \"data\": [\"data:image/png;base64,'$(base64 -w0 -i text_recognizer/tests/support/paragraphs/a01-077.png)'\"] }') \\\n",
    "  | curl -s -X POST \"https://d8f48ef7be822a0319.gradio.live/run/predict\" -H 'Content-Type: application/json' -d @-\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tLy9z593X4_o"
   },
   "source": [
    "JSON, short for \"JavaScript Object Notation\",\n",
    "is effectively the standard for representing dictionaries\n",
    "when sharing information between applications\n",
    "that may be written in different languages.\n",
    "\n",
    "With the standard library's `json.loads`,\n",
    "we can convert the response into a Python dictionary\n",
    "and then access the response `data` within."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GL4L8o4KRQLx"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "print(json.loads(response)[\"data\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rhOc0fgrRtuO"
   },
   "source": [
    "Importantly, the `echo | curl` command\n",
    "does not need to be run from the same machine that is running the model --\n",
    "that's another big win for this UI over the CLI script we ran previously.\n",
    "\n",
    "Try running the command from your own machine,\n",
    "if you are running OS X or Linux,\n",
    "and see if you can get a response.\n",
    "\n",
    "Don't forget to define the `API_URL` environment variable on your machine\n",
    "and download the image file,\n",
    "`text_recognizer/tests/support/paragraphs/a01-077.png`,\n",
    "changing the path if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cd1UZiM3ZVWz"
   },
   "source": [
    "Once you're done,\n",
    "turn off the Gradio interface by running the `.close` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "mVyv6KjxJhEb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n"
     ]
    }
   ],
   "source": [
    "frontend.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qnJpCdI7SHiX"
   },
   "source": [
    "## Testing our UI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've added a lot of new functionality here,\n",
    "and some of it is critical to our application.\n",
    "\n",
    "The surface area is too large and\n",
    "the components too complex for testing in depth\n",
    "to  be worth the investment --\n",
    "do we really want to set up a\n",
    "[headless browser](https://www.browserstack.com/guide/what-is-headless-browser-testing)\n",
    "or similar mock test to check whether our README is being loaded properly?\n",
    "\n",
    "So once again, we pick the minimal test that checks whether\n",
    "the core functionality is working:\n",
    "we spin up our frontend and ping the API,\n",
    "making sure we get back a\n",
    "[`200 OK`](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/200)\n",
    "response, indicating that at least the server thinks everything is fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'cat' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!cat app_gradio/tests/test_app.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IwUhy-swZndq"
   },
   "source": [
    "## Start here, finish anywhere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FTKMGCasMznl"
   },
   "source": [
    "You may be concerned:\n",
    "is `gradio` a children's toy?\n",
    "am I painting myself into a corner\n",
    "by using such a high-level framework and doing web development in Python?\n",
    "shouldn't I be using Ruby On Rails/Angular/React/WhateversNext.js?\n",
    "\n",
    "DALL-E Mini, now\n",
    "[crAIyon](https://www.craiyon.com/),\n",
    "began its life as\n",
    "[a Gradio app](https://huggingface.co/spaces/dalle-mini/dalle-mini)\n",
    "built by FSDL alumnus\n",
    "[Boris Dayma](https://twitter.com/borisdayma).\n",
    "\n",
    "Gradio and similar tools\n",
    "are critical for quickly getting to an MVP\n",
    "and getting useful feedback on your model.\n",
    "\n",
    "Expend your engineering effort on data and training,\n",
    "not frontend interface development,\n",
    "until you're sure you've got something people want to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8BpPtj6tsP-Y"
   },
   "source": [
    "# Wrapping a model into a model service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ButF0a6PSbMi"
   },
   "source": [
    "We've got an interactive interface for our model\n",
    "that we can share with friends, colleagues,\n",
    "potential users, or stakeholders,\n",
    "which is huge.\n",
    "\n",
    "But we have a problem:\n",
    "our model is running in the same place as our frontend.\n",
    "\n",
    "This is simple,\n",
    "but it ties too many things together.\n",
    "\n",
    "First, it ties together execution of the two components.\n",
    "\n",
    "If the model has a heart attack due to misformatted inputs\n",
    "or some mysterious DNN bug,\n",
    "the server goes down.\n",
    "The same applies in reverse --\n",
    "the only API for the model is provided by `gradio`,\n",
    "so a frontend issue means the model is inaccessible.\n",
    "\n",
    "Additionally, it ties together dependencies,\n",
    "since our server and our model are in the same\n",
    "environment.\n",
    "\n",
    "Lastly, it ties together the hardware used to run our\n",
    "server and our model.\n",
    "\n",
    "That's bad because the server and the model scale differently.\n",
    "Running the server at scale has different memory and computational requirements\n",
    "than does running the model at scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HNoMc7fRcETy"
   },
   "source": [
    "We could just run another server --\n",
    "even writing it in Gradio if we wanted! --\n",
    "for the model.\n",
    "This is common with GPU inference,\n",
    "especially when doing queueing, cacheing,\n",
    "and other advanced techniques for improving\n",
    "model efficiency and latency.\n",
    "\n",
    "But that's potentially expensive --\n",
    "we're running two machines,\n",
    "which costs twice as much.\n",
    "\n",
    "Furthermore, this setup is harder to scale \"horizontally\".\n",
    "\n",
    "We'll pretty quickly need a solution for auto-scaling\n",
    "our two servers independently,\n",
    "e.g. directly in a container orchestration service, like\n",
    "[Kubernetes](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/),\n",
    "or in a managed version of the same, like\n",
    "[Elastic Kubernetes Service](https://aws.amazon.com/eks/),\n",
    "or with an infrastructure automation tool, like\n",
    "[Terraform](https://www.terraform.io/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0WI0H6Imcz_h"
   },
   "source": [
    "Luckily, there is an easier way, because our model service-plus-UI\n",
    "combo fits into a common pattern.\n",
    "\n",
    "We have a server that we want to be up all the time,\n",
    "ready to take requests,\n",
    "but we really only need\n",
    "the model service to run when a request hits.\n",
    "\n",
    "And apart from its environment (which includes the weights),\n",
    "the model only needs the request in order to produce a result.\n",
    "\n",
    "It does not need to hold onto any information in between executions --\n",
    "it is _stateless_.\n",
    "\n",
    "This pattern is common enough that all cloud providers\n",
    "offer a solution that takes the pain out of scaling\n",
    "the stateless component:\n",
    "\"serverless cloud functions\",\n",
    "so named because\n",
    "- they are run intermittently, rather than 24/7, like a server.\n",
    "- they are run on cloud infrastructure.\n",
    "- they are, as in\n",
    "[purely functional programming](https://en.wikipedia.org/wiki/Purely_functional_programming)\n",
    "or in mathematics, \"pure\" functions of their inputs,\n",
    "with no concept of state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eE_FhWxLhhxG"
   },
   "source": [
    "We use AWS's serverless offering,\n",
    "[AWS Lambda](https://aws.amazon.com/lambda/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "xw3Una-yJ_mP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mType:\u001b[0m        module\n",
      "\u001b[1;31mString form:\u001b[0m <module 'api_serverless.api' from 'D:\\\\RL_Finance\\\\MLops\\\\fslab\\\\lab07\\\\api_serverless\\\\api.py'>\n",
      "\u001b[1;31mFile:\u001b[0m        d:\\rl_finance\\mlops\\fslab\\lab07\\api_serverless\\api.py\n",
      "\u001b[1;31mSource:\u001b[0m     \n",
      "\u001b[1;34m\"\"\"AWS Lambda function serving text_recognizer predictions.\"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImageStat\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[0mtext_recognizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparagraph_text_recognizer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mParagraphTextRecognizer\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mimport\u001b[0m \u001b[0mtext_recognizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParagraphTextRecognizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mdef\u001b[0m \u001b[0mhandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Provide main prediction API.\"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"INFO loading image\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_load_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"statusCode\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m400\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"message\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"neither image_url nor image found in event\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"INFO image loaded\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"INFO starting inference\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"INFO inference complete\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mimage_stat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImageStat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"METRIC image_mean_intensity {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_stat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"METRIC image_area {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"METRIC pred_length {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"INFO pred {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"pred\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mdef\u001b[0m \u001b[0m_load_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mevent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_from_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mevent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_from_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"body\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mimage_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"image_url\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[0mimage_url\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"INFO url {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_image_pil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrayscale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"image\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"INFO reading image from event\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mreturn\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_b64_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrayscale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mdef\u001b[0m \u001b[0m_from_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mevent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m"
     ]
    }
   ],
   "source": [
    "from api_serverless import api\n",
    "\n",
    "api??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FGAeXmfFiYOi"
   },
   "source": [
    "Our main function here, `api.handler`, wraps `ParagraphTextRecognizer.predict`.\n",
    "\n",
    "Effectively, `api.handler` maps HTTP requests (`event`s) with AWS's canonical format\n",
    "to a format our `ParagraphTextRecognizer` understands,\n",
    "then converts the text recognizer's output into something\n",
    "that AWS understands.\n",
    "\n",
    "Deploying models as web services is an exercise in taking\n",
    "the Tensor-to-Tensor-mappings we work with in model development\n",
    "and wrapping them so that they run in the\n",
    "JSON-to-JSON-mapping world of web services."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TDMPQKXqr7pS"
   },
   "source": [
    "## Talking to a model service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V41-UiMct92x"
   },
   "source": [
    "Setting up a serverless function on AWS requires an account\n",
    "(which requires putting down a credit card)\n",
    "and configuration of permissions\n",
    "(which is error-prone).\n",
    "\n",
    "If you want to see how that process works,\n",
    "check out our\n",
    "[\"bonus notebook\" on serverless deployment on AWS Lambda](https://github.com/full-stack-deep-learning/fsdl-text-recognizer-2022/blob/main/notebooks/lab99_serverless_aws.ipynb).\n",
    "Heads up: it uses Docker,\n",
    "which means it's not compatible with Google Colab.\n",
    "\n",
    "So we'll skip that step and,\n",
    "like Julia Child or Martha Stewart, check out\n",
    "[one that was prepared earlier](https://tvtropes.org/pmwiki/pmwiki.php/Main/OneIPreparedEarlier).\n",
    "\n",
    "The cell below sends a request\n",
    "to a serverless cloud function running on the FSDL AWS account.\n",
    "\n",
    "This request is\n",
    "much like the one we sent to the API provided by `gradio`,\n",
    "but we here construct and send it in Python,\n",
    "using the `requests` library,\n",
    "rather than operating from the command line.\n",
    "\n",
    "When playing around with an API,\n",
    "writing requests and parsing responses \"by hand\"\n",
    "in the command line is helpful,\n",
    "but once we're working on real use cases for the API,\n",
    "we'll want to use higher-level libraries\n",
    "with good code quality and nice integrations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "76HwEP2Vzz3F"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403\n",
      "{\"Message\":\"Forbidden\"}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'pred'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(response\u001b[38;5;241m.\u001b[39mstatus_code)  \u001b[38;5;66;03m# Check the HTTP status code\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(response\u001b[38;5;241m.\u001b[39mtext)  \u001b[38;5;66;03m# Print the full response body\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpred\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# the response is also json\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(pred)\n\u001b[0;32m     22\u001b[0m Image(url\u001b[38;5;241m=\u001b[39mimage_url, width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'pred'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from IPython.display import Image\n",
    "import requests  # the preferred library for writing HTTP requests in Python\n",
    "\n",
    "lambda_url = \"https://3akxma777p53w57mmdika3sflu0fvazm.lambda-url.us-west-1.on.aws/\"\n",
    "image_url = \"https://fsdl-public-assets.s3-us-west-2.amazonaws.com/paragraphs/a01-077.png\"\n",
    "\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "payload = json.dumps({\"image_url\": image_url})\n",
    "\n",
    "response = requests.post(  # we POST the image to the URL, expecting a prediction as a response\n",
    "    lambda_url, data=payload, headers=headers)\n",
    "\n",
    "\n",
    "print(response.status_code)  # Check the HTTP status code\n",
    "print(response.text)  # Print the full response body\n",
    "pred = response.json()[\"pred\"]  # the response is also json\n",
    "\n",
    "print(pred)\n",
    "\n",
    "Image(url=image_url, width=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before deploying a service like this one,\n",
    "it's important to check how well it handles different traffic volumes and patterns.\n",
    "This process is known as _load-testing_.\n",
    "\n",
    "For a quick tutorial on some basic tooling and a run-through of\n",
    "results from load-testing the FSDL Text Recognizer on AWS Lambda, see\n",
    "[this \"bonus notebook\" on load-testing](https://fsdl.me/loadtesting-colab)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bZQ2Dt4URN9o"
   },
   "source": [
    "## Local in the front, serverless in the back"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XMXWTHt4Pxpr"
   },
   "source": [
    "The primary \"win\" here\n",
    "is that we don't need to run\n",
    "the frontend UI server\n",
    "and the backend model service in\n",
    "the same place.\n",
    "\n",
    "For example,\n",
    "we can run a Gradio app locally\n",
    "but send the images to the serverless function\n",
    "for prediction.\n",
    "\n",
    "Our `app_gradio` implementation supports this via the `PredictorBackend`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4qZ1K0fwOtYK"
   },
   "outputs": [],
   "source": [
    "serverless_backend = app.PredictorBackend(url=lambda_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5NVVU2JEPSpy"
   },
   "source": [
    "Previously, our `PredictorBackend`\n",
    "was just a wrapper around the `ParagraphTextRecognizer` class.\n",
    "\n",
    "By passing a URL,\n",
    "we switch to sending data elsewhere via an HTTP request.\n",
    "\n",
    "This is done by the\n",
    "`_predict_from_endpoint` method,\n",
    "which runs effectively the same code we used\n",
    "to talk to the model service in the cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HtSppJq2O_B_"
   },
   "outputs": [],
   "source": [
    "serverless_backend._predict_from_endpoint??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DKA68zxUUO9e"
   },
   "source": [
    "The frontend doesn't care where the inference is getting done or how.\n",
    "\n",
    "A `gradio.Interface`\n",
    "just knows there's a Python function that it invokes and then \n",
    "waits for outputs from.\n",
    "\n",
    "Here, that Python function\n",
    "makes a request to the serverless backend,\n",
    "rather than running the model.\n",
    "\n",
    "Go ahead and try it out!\n",
    "\n",
    "You won't notice a difference,\n",
    "except that the machine you're running this notebook on\n",
    "no longer runs the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WEkMzohnOcK0"
   },
   "outputs": [],
   "source": [
    "frontend_serverless_backend = app.make_frontend(serverless_backend.run)\n",
    "\n",
    "frontend_serverless_backend.launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XytXrIWVuRFu"
   },
   "source": [
    "# Serving a `gradio` app with `ngrok`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2i64HrL1wa7F"
   },
   "source": [
    "We've now got a model service and a web server\n",
    "that we can stand up and scale independently,\n",
    "but we're not quite done yet.\n",
    "\n",
    "First, our URL is controlled by Gradio.\n",
    "\n",
    "Very quickly once we leave the territory of a minimal demo,\n",
    "we'll want that URL to be branded.\n",
    "\n",
    "Relatedly,\n",
    "you may have noticed messages indicating that the public URL\n",
    "from Gradio is only good for 72 hours.\n",
    "\n",
    "That means we'd have to reset our frontend\n",
    "and share a new URL every few days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "clsPvqtJu0V0"
   },
   "source": [
    "For projects that are mostly intended as public demos,\n",
    "you might follow the advice from those printed warnings\n",
    "and use\n",
    "[Hugging Face Spaces](https://huggingface.co/docs/hub/spaces)\n",
    "for free, permanent hosting.\n",
    "\n",
    "This relieves you of the burden of keeping the frontend server running.\n",
    "\n",
    "However, note that this requires you to use the Hugging Face Hub\n",
    "as a remote for your `git` repository, alongside GitHub or GitLab.\n",
    "This connection to the version control system can make for tricky integration,\n",
    "e.g. the need to create a new repository for each new model.\n",
    "\n",
    "By default, the demo is embedded inside Hugging Face,\n",
    "limiting your control over the look and feel.\n",
    "\n",
    "However, you can embed the demo in another website with\n",
    "[Web Components or IFrames](https://gradio.app/sharing_your_app/#embedding-with-web-components).\n",
    "You can also adapt the aesthetics and interactivity of the demo with\n",
    "[custom CSS and JS](https://gradio.app/custom_CSS_and_JS/).\n",
    "\n",
    "We will instead run the frontend server ourselves\n",
    "and provide a public URL\n",
    "without relying on Gradio's service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XWxKXSSG0yNX"
   },
   "source": [
    "Half of the work is already done for us:\n",
    "the `gradio` frontend is already listening on a port and IP address\n",
    "that is accessible locally\n",
    "(on `127.0.0.1` or `localhost`, as printed below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ugupgc1bxQlH"
   },
   "outputs": [],
   "source": [
    "frontend_serverless_backend.local_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GWcQa-ks1Ktn"
   },
   "source": [
    "So we can, for example, send `curl` requests locally,\n",
    "i.e. on the same machine as the frontend,\n",
    "and get responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z4JRaVjH0kPw"
   },
   "outputs": [],
   "source": [
    "# we send an improperly formatted request, because we just want to check for a response\n",
    "\n",
    "!curl -X POST {frontend_serverless_backend.local_url}api/predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZK4-tPGf32Hf"
   },
   "source": [
    "Running the same command on another machine will result in an error --\n",
    "`127.0.0.1` and `localhost` always mean \"on this machine\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eiwa6INa0PGe"
   },
   "source": [
    "So fundamentally,\n",
    "the goal is to take the frontend service\n",
    "running on an IP and port that is only accessible locally\n",
    "and make it accessible globally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cuuj13Xk0M0Q"
   },
   "source": [
    "There's some tricky bits here --\n",
    "for example, you'll want to communicate using encryption,\n",
    "i.e. over HTTPS instead of HTTP --\n",
    "that make doing this entirely on your own\n",
    "a bit of a headache.\n",
    "\n",
    "To avoid these issues,\n",
    "we can once again use\n",
    "[`ngrok`](https://ngrok.com/),\n",
    "the service we used to provide access to our Label Studio instance\n",
    "in the data annotation lab.\n",
    "\n",
    "The free tier includes public URLs and secure communication with HTTPS.\n",
    "\n",
    "However, the URL changes each time you relaunch your service,\n",
    "e.g. after an outage or a version update.\n",
    "\n",
    "The paid tier allows for branded domains,\n",
    "simpler authentication with\n",
    "[OAuth](https://oauth.net/),\n",
    "and some basic scaling tools like load balancing.\n",
    "\n",
    "This is what we use for the official FSDL text recognizer at\n",
    "[fsdl-text-recognizer.ngrok.io](https://fsdl-text-recognizer.ngrok.io/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IoKA_VUr4Gf2"
   },
   "source": [
    "To get started, let's\n",
    "set up our `ngrok` credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3N2jkwdaLZAu"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "from pyngrok import ngrok\n",
    "\n",
    "config_file = ngrok.conf.DEFAULT_NGROK_CONFIG_PATH\n",
    "config_file_exists =  os.path.exists(config_file)\n",
    "config_file_contents = !cat {config_file}\n",
    "\n",
    "auth_token_found = config_file_exists \\\n",
    "    and config_file_contents \\\n",
    "    and \"authtoken\" in config_file_contents[0] \\\n",
    "    and \": exit\" not in config_file_contents  # state if interrupted\n",
    "\n",
    "if not auth_token_found:\n",
    "    print(\"Enter your ngrok auth token, which can be copied from https://dashboard.ngrok.com/auth\")\n",
    "    !ngrok authtoken {getpass.getpass()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m3SaBJn14YA_"
   },
   "source": [
    "From there,\n",
    "it's as simple as pointing\n",
    "an `ngrok` tunnel\n",
    "at the port associated with your frontend.\n",
    "\n",
    "> For our purposes, ports are\n",
    "\"places you can listen for messages to your web service\".\n",
    "By separating ports,\n",
    "which are identifiers within a machine,\n",
    "from URLs/IPs,\n",
    "which are identifiers across machines,\n",
    "we can run multiple services on a single machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wURZiaA5LkeF"
   },
   "outputs": [],
   "source": [
    "TEXT_RECOGNIZER_PORT = frontend_serverless_backend.server_port\n",
    "\n",
    "https_tunnel = ngrok.connect(TEXT_RECOGNIZER_PORT, bind_tls=True)\n",
    "print(https_tunnel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Head to the printed `ngrok.io` URL from any device --\n",
    "e.g. a mobile phone --\n",
    "to check out your shiny new ML-powered application UI\n",
    "with serverless backend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XWYBGHLs5iwN"
   },
   "source": [
    "Running a web service out of a Jupyter notebook is not recommended.\n",
    "\n",
    "`gradio` and `ngrok`\n",
    "can be run from the command line.\n",
    "\n",
    "If you're running the lab locally,\n",
    "just define the `TEXT_RECOGNIZER_PORT`\n",
    "and `LAMBDA_URL` environment variables\n",
    "and then run\n",
    "\n",
    "```bash\n",
    "python app_gradio/app.py --model_url $LAMBDA_URL --model_port $TEXT_RECOGNIZER_PORT\n",
    "```\n",
    "\n",
    "in one terminal\n",
    "and, in a separate terminal,\n",
    "run\n",
    "```bash\n",
    "ngrok $TEXT_RECOGNIZER_PORT https\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nycSygTy-PcQ"
   },
   "source": [
    "and navigate to the printed URL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oQCpzYzHRGfd"
   },
   "source": [
    "## Launching a server on a cloud instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RKKnzQjmQPV8"
   },
   "source": [
    "We are almost, but not quite,\n",
    "to the point of a reasonably professional web service.\n",
    "\n",
    "The last missing piece is that our server is running\n",
    "either on Colab,\n",
    "which has short uptimes and is not intended for serving,\n",
    "or on our own personal machine,\n",
    "which is also likely a few\n",
    "[nines](https://en.wikipedia.org/wiki/High_availability#Percentage_calculation) short of an uptime SLA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IKOuYfpTQR-c"
   },
   "source": [
    "We want to instead run this on a dedicated server,\n",
    "and the simplest way to do so is to spin up a machine in a cloud provider.\n",
    "\n",
    "[Elastic Compute Cloud](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/concepts.html)\n",
    "(aka EC2)\n",
    "is the option in AWS,\n",
    "our chosen cloud provider."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "15NI6gI1746O"
   },
   "source": [
    "To get the server going on another machine,\n",
    "we'll need to `git clone` our library,\n",
    "`pip install` our `prod` requirements,\n",
    "and then finally run `ngrok` and `app_gradio/app.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "faStq6aV-hci"
   },
   "source": [
    "We can make that process slightly easier\n",
    "by incorporating it into a `Dockerfile`\n",
    "and building a container image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_1i0M7hR-moU"
   },
   "outputs": [],
   "source": [
    "!cat app_gradio/Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jskTeGs9AroE"
   },
   "source": [
    "We can then store the container image in a registry, like\n",
    "[Docker Hub](https://hub.docker.com/)\n",
    "or the container image registry built into our cloud provider, like AWS's\n",
    "[Elastic Container Registry](https://aws.amazon.com/ecr/).\n",
    "\n",
    "Then, setup just means pulling the image down onto the machine\n",
    "we want to run our server from and executing a `docker run` command."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
